{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chessown.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RedDawe/Reinforcement_Chess/blob/master/chessown.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRcddUy4EPuU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow-gpu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kZUVYNJBCBr",
        "colab_type": "code",
        "outputId": "399fb8ed-65a9-4841-d21d-02c9c12fe087",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "assert tf.executing_eagerly()\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIbTkUvsGfNC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "np.random.seed(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbzvYt527CIy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  e = 0\n",
        "\n",
        "  n = 1\n",
        "  q = 2\n",
        "  r = 3\n",
        "  b = 4\n",
        "  k = 5\n",
        "  p = 6\n",
        "\n",
        "  N = -1\n",
        "  Q = -2\n",
        "  R = -3\n",
        "  B = -4\n",
        "  K = -5\n",
        "  P = -6"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvK1eaN_Exo0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def one_hot(array, n_classes):\n",
        "  return np.array(tf.keras.backend.one_hot(array, n_classes))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxQjTTrqSnpD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def flip(array):\n",
        "  return np.flip(array, axis=0)*-1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWTUlcciBQc9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_board():\n",
        "  board = [[r, k, b, q, n, b, k, r],\n",
        "          [p, p, p, p, p, p, p, p],\n",
        "          [e, e, e, e, e, e, e, e],\n",
        "          [e, e, e, e, e, e, e, e],\n",
        "          [e, e, e, e, e, e, e, e],\n",
        "          [e, e, e, e, e, e, e, e],\n",
        "          [P, P, P, P, P, P, P, P],\n",
        "          [R, K, B, Q, N, B, K, R]\n",
        "  ]\n",
        "\n",
        "  board = np.array(board)\n",
        "\n",
        "  return board"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qssdgNyQBTzJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "def weighted_loss(weights):\n",
        "\n",
        "  def __weighted_loss(logits, labels):\n",
        "    return tf.keras.backend.mean(tf.keras.backend.square(logits - labels) * weights)\n",
        "    \n",
        "  return __weighted_loss\n",
        "\"\"\"\n",
        "\n",
        "def weighted_loss(logits, labels):\n",
        "  weights = labels[1, :, :, :]\n",
        "  labels = labels[0, :, :, :]\n",
        "  logits = tf.keras.backend.clip(logits, tf.keras.backend.epsilon(), 1-tf.keras.backend.epsilon())\n",
        "\n",
        "  #return tf.keras.backend.mean(tf.keras.backend.square(logits - labels) * weights)\n",
        "  return tf.keras.backend.mean(labels * -tf.math.log(logits) * weights)\n",
        "\n",
        "\n",
        "inputs = tf.keras.Input(shape=(8, 8,  2*p+1), dtype='float32')\n",
        "#weights = tf.keras.Input(shape=(8, 8, 2*p+1), dtype='float32')\n",
        "\n",
        "#model = tf.keras.layers.BatchNormalization()(inputs)\n",
        "model = inputs\n",
        "#model = tf.keras.backend.one_hot(tf.keras.backend.cast(inputs+p, 'int32'), 2*p+1)\n",
        "#model = tf.keras.backend.cast(model, 'float32')\n",
        "\n",
        "for i in range(32):\n",
        "  cell = tf.keras.layers.Conv2D(filters=2*p+1, kernel_size=[1, 1], activation='elu', padding='same')(model)\n",
        "  cell = tf.keras.layers.Conv2D(filters=4, kernel_size=[3, 3], activation='elu', padding='same')(cell)\n",
        "  cell = tf.keras.layers.BatchNormalization()(cell)\n",
        "  model = tf.keras.layers.Concatenate()(list([model, cell]))\n",
        "\n",
        "model = tf.keras.layers.Conv2D(filters=2*p+1, kernel_size=[1, 1], activation='linear', padding='same')(model)\n",
        "model = tf.keras.layers.Reshape([-1, 2*p+1])(model)\n",
        "model = tf.keras.layers.Softmax(axis=-1)(model)\n",
        "model = tf.keras.layers.Reshape([8, 8, 2*p+1])(model)\n",
        "\n",
        "model = tf.keras.Model(inputs=inputs, outputs=model)\n",
        "#model = tf.keras.Model(inputs=[inputs, weights], outputs=model)\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam', loss=weighted_loss)\n",
        "#model.compile(optimizer='adam', loss=weighted_loss(weights))\n",
        "#model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "#model.compile(optimizer='adam', loss='categorical_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsJIuLCVIQmN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_move(board, side, randomness=1):\n",
        "  if side:\n",
        "    board = flip(board)\n",
        "\n",
        "  #if np.random.randn(1)*0.5+0.5 < randomness:\n",
        "  if np.random.rand(1) <= randomness:\n",
        "    #logits =  model.predict([np.expand_dims(board, 0), np.zeros([1, 8, 8])])\n",
        "    logits =  model.predict([np.expand_dims(one_hot(board+p, 2*p+1), 0), np.zeros([1, 8, 8])])[0, :, :, :]\n",
        "    piece, to = decide_move(board, logits)\n",
        "  else:\n",
        "    piece, to = random_move(board)\n",
        "\n",
        "\n",
        "  if piece and to:\n",
        "    \"\"\"\n",
        "    if side:\n",
        "      print(flip(board), piece, to, sep='\\n')\n",
        "    else:\n",
        "      print(board, piece, to, sep='\\n')\n",
        "    \"\"\"\n",
        "    if board[to[0], to[1]] == N or board[to[0], to[1]] == n:\n",
        "      sys.exit()\n",
        "\n",
        "\n",
        "    board[to[0], to[1]] = board[piece[0], piece[1]]\n",
        "    board[piece[0], piece[1]] = e\n",
        "\n",
        "    weights_arr = np.zeros([8, 8])\n",
        "    weights_arr[to[0], to[1]] = 1\n",
        "    weights_arr[piece[0], piece[1]] = 1\n",
        "\n",
        "    if side:\n",
        "      return flip(board), np.flip(weights_arr, axis=0)\n",
        "    else:\n",
        "      return board, weights_arr\n",
        "  else:\n",
        "    return 'game_over', np.zeros([8, 8])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgyWP1k8JRFZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decide_move(board, logits):\n",
        "  biggest_diff = 1 #0\n",
        "  piece = []\n",
        "  to = []\n",
        "\n",
        "  for i in range(8):\n",
        "    for j in range(8):\n",
        "      #if abs(board[i, j] - logits[i, j]) > biggest_diff:\n",
        "      #if -(logits[i, j] - board[i, j]) > biggest_diff:\n",
        "      if board[i, j] > 0:\n",
        "        if logits[i, j] / board[i, j] < biggest_diff:\n",
        "          moves = get_possible_moves(board, [i, j])\n",
        "\n",
        "          for move in moves:\n",
        "            copy_board = np.copy(board)\n",
        "            copy_board[move[0], move[1]] = board[i, j]\n",
        "            copy_board[i, j] = e\n",
        "\n",
        "            if not is_check(flip(copy_board), N):\n",
        "              piece = [i, j]\n",
        "              to = [move[0], move[1]]\n",
        "\n",
        "  return piece, to"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TA2ibtmsFpa0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decide_move(board, logits):\n",
        "  biggest_diff = 0\n",
        "  piece = []\n",
        "  to = []\n",
        "\n",
        "  for i in range(8):\n",
        "    for j in range(8):\n",
        "      if board[i, j] > 0:\n",
        "        if 1 - logits[i, j, board[i, j]+p] > biggest_diff:\n",
        "          moves = get_possible_moves(board, [i, j])\n",
        "\n",
        "          smallest_diff = 0\n",
        "          for move in moves:\n",
        "            if logits[move[0], move[1], board[i, j]+p] > smallest_diff:\n",
        "              copy_board = np.copy(board)\n",
        "              copy_board[move[0], move[1]] = board[i, j]\n",
        "              copy_board[i, j] = e\n",
        "\n",
        "              if not is_check(flip(copy_board), N):\n",
        "                piece = [i, j]\n",
        "                to = [move[0], move[1]]\n",
        "\n",
        "  return piece, to"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iy7MovkO714Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def random_move(board):\n",
        "  I = list(range(8))\n",
        "  J = list(range(8))\n",
        "  np.random.shuffle(I)\n",
        "  np.random.shuffle(J)\n",
        "  piece = []\n",
        "  to = []\n",
        "\n",
        "  for i in I:\n",
        "    for j in J:\n",
        "      if board[i, j] > 0:\n",
        "        moves = get_possible_moves(board, [i, j])\n",
        "\n",
        "\n",
        "        np.random.shuffle(moves)\n",
        "\n",
        "        for move in moves:\n",
        "          copy_board = np.copy(board)\n",
        "          copy_board[move[0], move[1]] = board[i, j]\n",
        "          copy_board[i, j] = e\n",
        "\n",
        "          if not is_check(flip(copy_board), N):\n",
        "            piece = [i, j]\n",
        "            to = [move[0], move[1]]\n",
        "            break\n",
        "\n",
        "        if piece and to:\n",
        "          break\n",
        "\n",
        "    if piece and to:\n",
        "      break\n",
        "\n",
        "  return piece, to"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2JAuwFEBVxR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def is_check(board, piece):\n",
        "  coordinates = []\n",
        "\n",
        "  for i in range(8):\n",
        "    for j in range(8):\n",
        "      if board[i, j] == piece:\n",
        "        coordinates = [i, j]\n",
        "\n",
        "  check = False\n",
        "  for i in range(8):\n",
        "    for j in range(8):\n",
        "      if board[i, j] > 0 and not check:\n",
        "        moves = get_possible_moves(board, [i, j])\n",
        "        check = coordinates in moves\n",
        "\n",
        "  return check"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Oy0hHLEc1tc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_possible_moves(board, coordinates): #put together all moves that 'is_legal', are on the board and aren't taking your own pieces\n",
        "  legal_moves = []\n",
        "  for i in range(8):\n",
        "    for j in range(8):\n",
        "      if (board[coordinates[0], coordinates[1]] > 0 and board[i, j] <= 0) or (board[coordinates[0], coordinates[1]] < 0 and board[i, j] >= 0):\n",
        "        if is_legal(board, coordinates, [i, j]):\n",
        "          legal_moves.append([i, j])\n",
        "\n",
        "  return legal_moves"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-tchmQQcS5R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def is_legal(board, piece, move): #check if move is in a direction that the piece moves andif squares between start and finish are empty\n",
        "  if board[piece[0], piece[1]] == n: #KINGS\n",
        "    return abs(piece[0] - move[0]) <= 1 and abs(piece[1] - move[1]) <= 1\n",
        "\n",
        "  elif board[piece[0], piece[1]] == q: #QUEEN\n",
        "    if abs(piece[0] - move[0]) == 0:\n",
        "      if abs(piece[1] - move[1]) >= 2:\n",
        "        return np.all(board[min([piece[1], move[1]])+1 : max([piece[1], move[1]])] == e)\n",
        "      else:\n",
        "        return True\n",
        "    elif abs(piece[1] - move[1]) == 0:\n",
        "      if abs(piece[0] - move[0]) >= 2:\n",
        "        return np.all(board[min([piece[0], move[0]])+1 : max([piece[0], move[0]])] == e)\n",
        "      else:\n",
        "        return True\n",
        "    elif abs(piece[0] - move[0]) == abs(piece[1] - move[1]):\n",
        "\n",
        "      distance = abs(piece[0] - move[0])\n",
        "      vertically = np.arange(distance) * (1 if piece[0] < move[0] else -1)\n",
        "      horizontally = np.arange(distance) * (1 if piece[1] < move[1] else -1)\n",
        "\n",
        "      empty = True\n",
        "      for i in range(1, distance):\n",
        "        if board[piece[0]+vertically[i], piece[1]+horizontally[i]] != e:\n",
        "          empty = False\n",
        "\n",
        "      return empty\n",
        "    else:\n",
        "      return False\n",
        "\n",
        "  elif board[piece[0], piece[1]] == r: #ROOK\n",
        "    if abs(piece[0] - move[0]) == 0:\n",
        "      if abs(piece[1] - move[1]) >= 2:\n",
        "        return np.all(board[min([piece[1], move[1]])+1 : max([piece[1], move[1]])] == e)\n",
        "      else:\n",
        "        return True\n",
        "    elif abs(piece[1] - move[1]) == 0:\n",
        "      if abs(piece[0] - move[0]) >= 2:\n",
        "        return np.all(board[min([piece[0], move[0]])+1 : max([piece[0], move[0]])] == e)\n",
        "      else:\n",
        "        return True\n",
        "    else:\n",
        "      return False\n",
        "\n",
        "  elif board[piece[0], piece[1]] == b: #BISHOP\n",
        "    if abs(piece[0] - move[0]) == abs(piece[1] - move[1]):\n",
        "\n",
        "      distance = abs(piece[0] - move[0])\n",
        "      vertically = np.arange(distance) * (1 if piece[0] < move[0] else -1)\n",
        "      horizontally = np.arange(distance) * (1 if piece[1] < move[1] else -1)\n",
        "\n",
        "      empty = True\n",
        "      for i in range(1, distance):\n",
        "        if board[piece[0]+vertically[i], piece[1]+horizontally[i]] != e:\n",
        "          empty = False\n",
        "\n",
        "      return empty\n",
        "\n",
        "    else:\n",
        "      return False\n",
        "\n",
        "  elif board[piece[0], piece[1]] == k: #KNIGHT\n",
        "    return (abs(piece[0] - move[0]) == 2 and abs(piece[0] - move[0]) == 1) or (abs(piece[0] - move[0]) == 1 and abs(piece[0] - move[0]) == 2)\n",
        "\n",
        "  elif board[piece[0], piece[1]] == p: #PAWN\n",
        "    return ((move[0] - piece[0]) == 1 and abs(piece[1] - move[1]) == 0 and board[move[0], move[1]] == e) or ((move[0] - piece[0]) == 1 and abs(piece[1] - move[1]) == 1 and board[move[0], move[1]] < 0)\n",
        "\n",
        "  else:\n",
        "    print('u fucked up')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZhngi3V0vsH",
        "colab_type": "code",
        "outputId": "6bbda210-fda6-4d4e-8062-e4128b30738a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "kokot = init_board()\n",
        "kokot[1, 1] = e\n",
        "print(kokot)\n",
        "print(is_legal(kokot, [0, 2], [2, 0]))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 3  5  4  2  1  4  5  3]\n",
            " [ 6  0  6  6  6  6  6  6]\n",
            " [ 0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0]\n",
            " [-6 -6 -6 -6 -6 -6 -6 -6]\n",
            " [-3 -5 -4 -2 -1 -4 -5 -3]]\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PpGP7sN9-ex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_steps = 200\n",
        "games_to_play = 100\n",
        "max_depth = 100\n",
        "epochs = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1WrL7byDkRR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_path = \"training_2/cp.ckpt\"\n",
        "\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xox7Gbqw9e54",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for step in range(0, n_steps):\n",
        "  print('STEP NUMBER:', step)\n",
        "\n",
        "  replay_memory = []\n",
        "\n",
        "  for game in range(games_to_play):\n",
        "    game_memory = []\n",
        "    board = init_board()\n",
        "    #print(\"NEW GAMEEEEEEEEEEE!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
        "\n",
        "    for depth in range(max_depth):\n",
        "      move, weights_arr = make_move(np.copy(board), False, step/n_steps)\n",
        "      if not (type(move) is np.ndarray):\n",
        "        win = 'black'\n",
        "        break\n",
        "      else:\n",
        "        game_memory.append([board, move, weights_arr])\n",
        "        board = np.copy(move)\n",
        "\n",
        "      move, weights_arr = make_move(np.copy(board), True, step/n_steps)\n",
        "      if not (type(move) is np.ndarray):\n",
        "        win = 'white'\n",
        "        break\n",
        "      else:\n",
        "        game_memory.append([flip(board), flip(move), np.flip(weights_arr, axis=0)])\n",
        "        #board = np.copy(flip(move))\n",
        "        board = np.copy(move)\n",
        "\n",
        "    else:\n",
        "      win = 'white' if np.sum(board) > 0 else 'black'\n",
        "\n",
        "    replay_memory.append([win, game_memory]) \n",
        "\n",
        "\n",
        "  x = []\n",
        "  w = []\n",
        "  y = []\n",
        "\n",
        "  for game in replay_memory:\n",
        "    result, moves = game\n",
        "\n",
        "    for iterator, data in enumerate(moves):\n",
        "      board, move, weights_arr = data\n",
        "\n",
        "      #x.append(one_hot(board, 2*p+1))\n",
        "      x.append(board)\n",
        "      #w.append(np.tile(np.expand_dims(weights_arr, -1), [1, 1, 13]))\n",
        "      w.append(weights_arr)\n",
        "      if (result == 'white' and iterator%2 == 0) or (result == 'black' and iterator%2 == 1):\n",
        "        #y.append(one_hot(move+p, 2*p+1))\n",
        "        y.append(move)\n",
        "      else:\n",
        "        #y.append(one_hot(board+p, 2*p+1))\n",
        "        y.append(board)\n",
        "\n",
        "  x = np.array(x)\n",
        "  w = np.array(w)\n",
        "  y = np.array(y)\n",
        "  yw = np.stack([y, w], 1)\n",
        "  \n",
        "  #model.fit(x=[x, w], y=y, epochs = epochs, callbacks=[cp_callback])\n",
        "  #model.fit(x=x, y=y, epochs = epochs, callbacks=[cp_callback])\n",
        "  model.fit(x=x, y=yw, epochs = epochs, callbacks=[cp_callback])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVI1QhLaDxC7",
        "colab_type": "code",
        "outputId": "7e784f73-8c58-44b1-ce88-c2236cd3fb9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "model.load_weights(checkpoint_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-5543ef22fa1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name)\u001b[0m\n\u001b[1;32m    179\u001b[0m         raise ValueError('Load weights is not yet supported with TPUStrategy '\n\u001b[1;32m    180\u001b[0m                          'with steps_per_run greater than 1.')\n\u001b[0;32m--> 181\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_automatic_dependency_tracking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name)\u001b[0m\n\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1143\u001b[0;31m         \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNewCheckpointReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m         \u001b[0msave_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'tf'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0merrors_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLossError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mNewCheckpointReader\u001b[0;34m(filepattern)\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mNewCheckpointReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mCheckpointReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[0mNewCheckpointReader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tf_api_names_v1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'train.NewCheckpointReader'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mthis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_pywrap_tensorflow_internal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_CheckpointReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to get matching files on training_1/cp.ckpt: Not found: training_1; No such file or directory"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaAblc1Gg9ji",
        "colab_type": "code",
        "outputId": "fbfafe7b-3f04-4140-e775-d64f46d827e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "actuall = init_board()\n",
        "one, two = make_move(actuall, False)\n",
        "print(one)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[0.04045615 0.13503076 0.07136621 0.06308165 0.06515583 0.05310563\n",
            "   0.06665693 0.13989195 0.05684811 0.10488531 0.05604027 0.05876524\n",
            "   0.08871595]\n",
            "  [0.05664025 0.09392781 0.05074177 0.07943127 0.06024208 0.03248367\n",
            "   0.06649629 0.12422331 0.05417711 0.1353962  0.04079612 0.13407326\n",
            "   0.07137083]\n",
            "  [0.08887113 0.06065777 0.08225497 0.09895473 0.05779774 0.04915271\n",
            "   0.05314228 0.12530081 0.06289372 0.1207284  0.06240023 0.08245656\n",
            "   0.05538896]\n",
            "  [0.06388096 0.0943485  0.06695353 0.09049567 0.0457959  0.08131938\n",
            "   0.04019959 0.16204101 0.05801721 0.07741291 0.04223995 0.11647137\n",
            "   0.06082403]\n",
            "  [0.0819439  0.08026277 0.06436513 0.05471571 0.05675073 0.04194325\n",
            "   0.05021402 0.11261645 0.09046061 0.06109706 0.05561333 0.13834567\n",
            "   0.11167137]\n",
            "  [0.04814825 0.08887824 0.05814101 0.08207323 0.05589648 0.05216939\n",
            "   0.08024685 0.11613324 0.06421359 0.14439712 0.06741749 0.07926934\n",
            "   0.06301571]\n",
            "  [0.05348623 0.06594437 0.07090746 0.09713892 0.04563185 0.05286398\n",
            "   0.04931632 0.17578657 0.05653624 0.10664174 0.06726568 0.10518751\n",
            "   0.05329317]\n",
            "  [0.05120803 0.04377882 0.06483294 0.08461452 0.04953542 0.06367065\n",
            "   0.0524727  0.09836442 0.09034639 0.09354947 0.12262145 0.07895469\n",
            "   0.10605053]]\n",
            "\n",
            " [[0.05831086 0.1031097  0.05708353 0.04226327 0.08365313 0.10169723\n",
            "   0.07650347 0.06067952 0.08909998 0.07692908 0.04105484 0.07372946\n",
            "   0.13588594]\n",
            "  [0.05037248 0.12687376 0.06476742 0.03439096 0.05606774 0.09609152\n",
            "   0.06613089 0.08609471 0.08727719 0.10638676 0.01403083 0.11154483\n",
            "   0.09997095]\n",
            "  [0.04353686 0.09495139 0.0444888  0.05195212 0.03617915 0.08662363\n",
            "   0.05405782 0.10821309 0.20509657 0.12727289 0.02086855 0.07630699\n",
            "   0.05045212]\n",
            "  [0.05469689 0.10943408 0.05101513 0.08333831 0.04094204 0.11684595\n",
            "   0.07980198 0.08101299 0.10261765 0.10924999 0.04354153 0.06798642\n",
            "   0.05951711]\n",
            "  [0.06078398 0.13607965 0.04898677 0.06167131 0.030835   0.12095017\n",
            "   0.0534929  0.07529685 0.07990535 0.15285383 0.02966533 0.07058565\n",
            "   0.07889315]\n",
            "  [0.06451808 0.09595896 0.08175217 0.05976529 0.04368117 0.10722595\n",
            "   0.06202308 0.07878953 0.1272555  0.10106155 0.03489332 0.0982842\n",
            "   0.04479122]\n",
            "  [0.05651112 0.07249951 0.08305728 0.07096446 0.05360882 0.09435137\n",
            "   0.05252972 0.09807625 0.09441235 0.1250915  0.05136411 0.08097689\n",
            "   0.0665566 ]\n",
            "  [0.06360024 0.06380114 0.0641685  0.09076764 0.03576431 0.07338324\n",
            "   0.04254005 0.09693383 0.20506862 0.0854756  0.05002104 0.08069235\n",
            "   0.04778345]]\n",
            "\n",
            " [[0.03139284 0.06834999 0.03744162 0.06243769 0.0773218  0.0890457\n",
            "   0.0681939  0.08006128 0.09216173 0.14818306 0.02106439 0.11910602\n",
            "   0.10523999]\n",
            "  [0.02047621 0.07080011 0.06160207 0.04821091 0.057586   0.05310819\n",
            "   0.0943917  0.07041332 0.09639763 0.15761313 0.02110639 0.15645066\n",
            "   0.09184376]\n",
            "  [0.01144312 0.04766025 0.09238648 0.06382219 0.05137262 0.04478743\n",
            "   0.06493935 0.09176253 0.12178929 0.19755001 0.01693826 0.13327074\n",
            "   0.06227773]\n",
            "  [0.00916416 0.03723769 0.06705575 0.0552353  0.03832259 0.06191916\n",
            "   0.07096957 0.08418644 0.18888757 0.1743909  0.01355444 0.1104704\n",
            "   0.08860605]\n",
            "  [0.01290789 0.04552802 0.07453614 0.04944006 0.04160108 0.05587038\n",
            "   0.0484395  0.09171912 0.15759847 0.18053538 0.01888978 0.1590431\n",
            "   0.06389105]\n",
            "  [0.01261185 0.03022498 0.068763   0.0488625  0.03139865 0.0616941\n",
            "   0.06811613 0.07351884 0.11635252 0.26675576 0.03128229 0.13532867\n",
            "   0.05509072]\n",
            "  [0.01508289 0.03265999 0.10955513 0.07193645 0.03112842 0.05416182\n",
            "   0.07497994 0.06603782 0.1057797  0.22942942 0.03869472 0.11898598\n",
            "   0.05156766]\n",
            "  [0.02062137 0.03917431 0.12225977 0.06108768 0.03158564 0.06664582\n",
            "   0.04898208 0.09064861 0.11908205 0.15527941 0.05512911 0.10526185\n",
            "   0.08424229]]\n",
            "\n",
            " [[0.04734534 0.07587849 0.04194592 0.06331669 0.1113216  0.09809565\n",
            "   0.05779853 0.06329712 0.07960998 0.11046579 0.03547136 0.08057425\n",
            "   0.13487932]\n",
            "  [0.02758287 0.07122318 0.03602872 0.06063094 0.10616804 0.084005\n",
            "   0.0744864  0.0593655  0.07999229 0.1545272  0.04316448 0.11774976\n",
            "   0.08507565]\n",
            "  [0.03019058 0.05030401 0.03832664 0.06325933 0.09216549 0.07988933\n",
            "   0.07302677 0.07318144 0.09851497 0.14728136 0.03056938 0.14840336\n",
            "   0.07488738]\n",
            "  [0.029061   0.05264392 0.03986318 0.07025786 0.09675449 0.0782372\n",
            "   0.08496632 0.07716184 0.10605279 0.13197853 0.04080492 0.10950938\n",
            "   0.08270851]\n",
            "  [0.02598153 0.04351104 0.04067735 0.08201547 0.09119696 0.07236376\n",
            "   0.07692335 0.06499463 0.09741016 0.13334203 0.02706027 0.15907837\n",
            "   0.08544508]\n",
            "  [0.02922894 0.04975942 0.0310447  0.09054784 0.08421332 0.06928949\n",
            "   0.06957068 0.05593276 0.12178308 0.15495731 0.02985989 0.12901549\n",
            "   0.08479703]\n",
            "  [0.03589404 0.04519797 0.04311104 0.09311513 0.06948303 0.08804227\n",
            "   0.06865503 0.06691016 0.11146987 0.12691765 0.04349002 0.15265141\n",
            "   0.05506237]\n",
            "  [0.04234649 0.04445186 0.10057063 0.08839775 0.04993986 0.08807925\n",
            "   0.06864272 0.06887958 0.08409635 0.11159277 0.03596954 0.13312705\n",
            "   0.08390613]]\n",
            "\n",
            " [[0.04955132 0.08074245 0.05049819 0.08716972 0.04758827 0.06871764\n",
            "   0.05591551 0.10646816 0.11461628 0.09555937 0.04456083 0.12483525\n",
            "   0.07377703]\n",
            "  [0.03162169 0.07107861 0.04250071 0.0688827  0.07039027 0.05278467\n",
            "   0.06127302 0.092824   0.09906859 0.14468491 0.04526156 0.15561116\n",
            "   0.0640181 ]\n",
            "  [0.03392787 0.05722521 0.05622744 0.07960998 0.04717974 0.04857215\n",
            "   0.06190445 0.12602489 0.11184952 0.09829435 0.02794342 0.20231417\n",
            "   0.0489268 ]\n",
            "  [0.02962099 0.06630918 0.04503629 0.07536446 0.0495941  0.04039688\n",
            "   0.05810301 0.12390762 0.15195833 0.10564305 0.02689719 0.17502378\n",
            "   0.05214504]\n",
            "  [0.03020285 0.0650541  0.0439877  0.07809991 0.04239169 0.03953411\n",
            "   0.04948854 0.12149759 0.11471674 0.14979145 0.03152195 0.19215997\n",
            "   0.04155344]\n",
            "  [0.03527538 0.08179111 0.04998497 0.10208749 0.05250207 0.0408003\n",
            "   0.05828071 0.09540591 0.12721768 0.11905599 0.03759741 0.14930093\n",
            "   0.05070012]\n",
            "  [0.0404523  0.05611127 0.05970955 0.06798747 0.06233853 0.05226257\n",
            "   0.0542096  0.0767026  0.09851748 0.1229868  0.03776075 0.20891626\n",
            "   0.06204483]\n",
            "  [0.04594967 0.04482019 0.15850095 0.08182094 0.05210489 0.05952975\n",
            "   0.05011352 0.06449216 0.06301121 0.11128418 0.02795334 0.17672117\n",
            "   0.06369802]]\n",
            "\n",
            " [[0.04716631 0.06246502 0.05918978 0.05512179 0.05811008 0.07305755\n",
            "   0.04313289 0.07235697 0.158287   0.08460554 0.07573898 0.09776845\n",
            "   0.11299962]\n",
            "  [0.02560674 0.070879   0.07094632 0.05958537 0.04482277 0.07673843\n",
            "   0.04000067 0.05777134 0.22638062 0.08861967 0.09473104 0.0752155\n",
            "   0.06870252]\n",
            "  [0.03343075 0.06037028 0.07035293 0.06449245 0.04956553 0.07317117\n",
            "   0.03725908 0.04837517 0.20387906 0.13418539 0.05256103 0.09199098\n",
            "   0.0803662 ]\n",
            "  [0.03455863 0.0746249  0.07245311 0.06287874 0.05122111 0.08258109\n",
            "   0.02848179 0.03833861 0.26902    0.09013253 0.05787785 0.0734199\n",
            "   0.06441174]\n",
            "  [0.03763917 0.05903469 0.05278994 0.06067131 0.05027823 0.06725121\n",
            "   0.03803913 0.0432885  0.25647438 0.10720593 0.06487179 0.09291893\n",
            "   0.06953679]\n",
            "  [0.02842072 0.07238707 0.06874029 0.06852482 0.05443845 0.0760733\n",
            "   0.04399184 0.04923153 0.21175946 0.08944171 0.05222931 0.1233201\n",
            "   0.06144136]\n",
            "  [0.01909464 0.05030518 0.07561465 0.04780496 0.04137351 0.07719124\n",
            "   0.04364593 0.0549652  0.25126615 0.16366239 0.04457868 0.06208325\n",
            "   0.06841423]\n",
            "  [0.04892243 0.05933033 0.11630743 0.07406033 0.05092265 0.07725064\n",
            "   0.0561322  0.04756771 0.11281314 0.15035652 0.04394571 0.10479851\n",
            "   0.05759238]]\n",
            "\n",
            " [[0.06596904 0.0465996  0.09841186 0.12540065 0.03646773 0.10290649\n",
            "   0.08366212 0.04867966 0.09286308 0.0654827  0.13071394 0.04974858\n",
            "   0.05309457]\n",
            "  [0.11372713 0.06089032 0.07915618 0.09227881 0.02736776 0.08418512\n",
            "   0.09653896 0.06177141 0.0980319  0.06101163 0.10955532 0.06878471\n",
            "   0.04670076]\n",
            "  [0.07997915 0.07555518 0.07254542 0.08736929 0.0439451  0.09951128\n",
            "   0.063781   0.04872319 0.10966742 0.09172435 0.0546611  0.10984629\n",
            "   0.06269127]\n",
            "  [0.0738846  0.04340953 0.09218913 0.06959634 0.04165001 0.13784555\n",
            "   0.07629137 0.07492524 0.09031181 0.09872793 0.07898807 0.06991015\n",
            "   0.05227024]\n",
            "  [0.05904832 0.05572969 0.05310491 0.07502539 0.02667311 0.11086942\n",
            "   0.1027732  0.068418   0.12604393 0.08671722 0.1040031  0.07444828\n",
            "   0.05714547]\n",
            "  [0.0811636  0.05572142 0.07563792 0.07724684 0.04862185 0.10308321\n",
            "   0.08213007 0.06497604 0.09375422 0.07607965 0.06037769 0.13269825\n",
            "   0.04850927]\n",
            "  [0.08246007 0.08652242 0.0760543  0.08190056 0.04413111 0.06802034\n",
            "   0.09624466 0.08601845 0.12004387 0.08202334 0.06026152 0.07324638\n",
            "   0.04307295]\n",
            "  [0.06151371 0.07047081 0.06993926 0.08341379 0.04748494 0.08759305\n",
            "   0.10757231 0.07086079 0.08680034 0.09167644 0.0586956  0.11260454\n",
            "   0.05137437]]\n",
            "\n",
            " [[0.08014006 0.05944921 0.05126794 0.04780655 0.07539418 0.05969235\n",
            "   0.06087391 0.07166775 0.13001943 0.11675227 0.08003938 0.09396349\n",
            "   0.07293348]\n",
            "  [0.10126034 0.0830597  0.05117607 0.06338067 0.0476782  0.11786819\n",
            "   0.05882937 0.09015841 0.03829879 0.07845617 0.12421963 0.08926003\n",
            "   0.05635445]\n",
            "  [0.06930283 0.08590734 0.06339855 0.07856327 0.04320021 0.05479369\n",
            "   0.10437872 0.1302727  0.07202461 0.0825915  0.06027414 0.06030682\n",
            "   0.09498557]\n",
            "  [0.06554071 0.07805686 0.02815308 0.07466313 0.05485122 0.08731092\n",
            "   0.08793653 0.1467379  0.05325398 0.07520586 0.09037532 0.0528002\n",
            "   0.10511425]\n",
            "  [0.05666312 0.08938324 0.07121003 0.08732849 0.05272613 0.09680872\n",
            "   0.07001312 0.11592343 0.08552123 0.09117056 0.06872534 0.05347532\n",
            "   0.06105128]\n",
            "  [0.05784624 0.05586068 0.05959842 0.09565622 0.04591224 0.08817386\n",
            "   0.05926354 0.09809854 0.07876556 0.08477428 0.08427464 0.08481807\n",
            "   0.10695778]\n",
            "  [0.08273689 0.11406364 0.05857422 0.08078557 0.05799126 0.06104921\n",
            "   0.06280269 0.10996862 0.04345426 0.06999375 0.1213245  0.06091654\n",
            "   0.07633882]\n",
            "  [0.05788381 0.07985449 0.09104443 0.07551201 0.07249357 0.04594032\n",
            "   0.08611648 0.08674182 0.07333621 0.0492463  0.09313115 0.07969723\n",
            "   0.10900217]]] [1, 7] [2, 7]\n",
            "[[ 3  5  4  2  1  4  5  3]\n",
            " [ 6  6  6  6  6  6  6  0]\n",
            " [ 0  0  0  0  0  0  0  6]\n",
            " [ 0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0]\n",
            " [-6 -6 -6 -6 -6 -6 -6 -6]\n",
            " [-3 -5 -4 -2 -1 -4 -5 -3]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMSFhSJwmkUN",
        "colab_type": "code",
        "outputId": "a8eefe3f-f4d5-47a4-b85a-bf11ec701ee7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "one[6, 4] = e\n",
        "one[4, 4] = P\n",
        "one, two = make_move(one, False)\n",
        "print(one)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 3  5  4  2  1  4  5  0]\n",
            " [ 0  6  6  0  6  6  6  3]\n",
            " [ 6  0  0  6  0  0  0  6]\n",
            " [ 0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 -6 -6  0  0]\n",
            " [ 0  0  0  0  0  0  0  0]\n",
            " [-6 -6 -6 -6  0  0 -6 -6]\n",
            " [-3 -5 -4 -2 -1 -4 -5 -3]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgsvfLBHmz91",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}