{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chessown.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RedDawe/Reinforcement_Chess/blob/master/chessown.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRcddUy4EPuU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow-gpu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kZUVYNJBCBr",
        "colab_type": "code",
        "outputId": "f2c0ae13-0e73-40c2-f887-18be9429f6e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "assert tf.executing_eagerly()\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIbTkUvsGfNC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "np.random.seed(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbzvYt527CIy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  e = 0\n",
        "\n",
        "  n = 1\n",
        "  q = 2\n",
        "  r = 3\n",
        "  b = 4\n",
        "  k = 5\n",
        "  p = 6\n",
        "\n",
        "  N = -1\n",
        "  Q = -2\n",
        "  R = -3\n",
        "  B = -4\n",
        "  K = -5\n",
        "  P = -6"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvK1eaN_Exo0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def one_hot(array, n_classes):\n",
        "  return np.array(tf.keras.backend.one_hot(array, n_classes))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxQjTTrqSnpD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def flip(array):\n",
        "  return np.flip(array, axis=0)*-1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWTUlcciBQc9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_board():\n",
        "  board = [[r, k, b, q, n, b, k, r],\n",
        "          [p, p, p, p, p, p, p, p],\n",
        "          [e, e, e, e, e, e, e, e],\n",
        "          [e, e, e, e, e, e, e, e],\n",
        "          [e, e, e, e, e, e, e, e],\n",
        "          [e, e, e, e, e, e, e, e],\n",
        "          [P, P, P, P, P, P, P, P],\n",
        "          [R, K, B, Q, N, B, K, R]\n",
        "  ]\n",
        "\n",
        "  board = np.array(board)\n",
        "\n",
        "  return board"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qssdgNyQBTzJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "def weighted_loss(weights):\n",
        "\n",
        "  def __weighted_loss(logits, labels):\n",
        "    return tf.keras.backend.mean(tf.keras.backend.square(logits - labels) * weights)\n",
        "    \n",
        "  return __weighted_loss\n",
        "\"\"\"\n",
        "\n",
        "def weighted_loss(logits, labels):\n",
        "  weights = labels[1]\n",
        "  labels = labels[0]\n",
        "  logits = tf.keras.backend.clip(logits, tf.keras.backend.epsilon(), 1-tf.keras.backend.epsilon())\n",
        "\n",
        "  #return tf.keras.backend.mean(tf.keras.backend.square(logits - labels) * weights)\n",
        "  return tf.keras.backend.mean(labels * -tf.math.log(logits) * weights)\n",
        "\n",
        "\n",
        "inputs = tf.keras.Input(shape=(8, 8,  2*p+1), dtype='float32')\n",
        "#weights = tf.keras.Input(shape=(8, 8, 2*p+1), dtype='float32')\n",
        "\n",
        "#model = tf.keras.layers.BatchNormalization()(inputs)\n",
        "model = inputs\n",
        "#model = tf.keras.backend.one_hot(tf.keras.backend.cast(inputs+p, 'int32'), 2*p+1)\n",
        "#model = tf.keras.backend.cast(model, 'float32')\n",
        "\n",
        "for i in range(32):\n",
        "  cell = tf.keras.layers.Conv2D(filters=2*p+1, kernel_size=[1, 1], activation='elu', padding='same')(model)\n",
        "  cell = tf.keras.layers.Conv2D(filters=4, kernel_size=[3, 3], activation='elu', padding='same')(cell)\n",
        "  cell = tf.keras.layers.BatchNormalization()(cell)\n",
        "  model = tf.keras.layers.Concatenate()(list([model, cell]))\n",
        "\n",
        "model = tf.keras.layers.Conv2D(filters=2*p+1, kernel_size=[1, 1], activation='linear', padding='same')(model)\n",
        "model = tf.keras.layers.Reshape([-1, 2*p+1])(model)\n",
        "model = tf.keras.layers.Softmax(axis=0)(model)\n",
        "model = tf.keras.layers.Reshape([8, 8, 2*p+1])(model)\n",
        "\n",
        "model = tf.keras.Model(inputs=inputs, outputs=model)\n",
        "#model = tf.keras.Model(inputs=[inputs, weights], outputs=model)\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam', loss=weighted_loss)\n",
        "#model.compile(optimizer='adam', loss=weighted_loss(weights))\n",
        "#model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "#model.compile(optimizer='adam', loss='categorical_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsJIuLCVIQmN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_move(board, side, randomness):\n",
        "  if side:\n",
        "    board = flip(board)\n",
        "\n",
        "  #if np.random.randn(1)*0.5+0.5 < randomness:\n",
        "  if np.random.rand(1) < randomness:\n",
        "    #logits =  model.predict([np.expand_dims(board, 0), np.zeros([1, 8, 8])])\n",
        "    logits =  model.predict([np.expand_dims(one_hot(board+p, 2*p+1), 0), np.zeros([1, 8, 8])])[0, :, :, :]\n",
        "    piece, to = decide_move(board, logits)\n",
        "  else:\n",
        "    piece, to = random_move(board)\n",
        "\n",
        "\n",
        "  if piece and to:\n",
        "    \"\"\"\n",
        "    if side:\n",
        "      print(flip(board), piece, to, sep='\\n')\n",
        "    else:\n",
        "      print(board, piece, to, sep='\\n')\n",
        "    \"\"\"\n",
        "    if board[to[0], to[1]] == N or board[to[0], to[1]] == n:\n",
        "      sys.exit()\n",
        "\n",
        "\n",
        "    board[to[0], to[1]] = board[piece[0], piece[1]]\n",
        "    board[piece[0], piece[1]] = e\n",
        "\n",
        "    weights_arr = np.zeros([8, 8])\n",
        "    weights_arr[to[0], to[1]] = 1\n",
        "    weights_arr[piece[0], piece[1]] = 1\n",
        "\n",
        "    return board, weights_arr\n",
        "  else:\n",
        "    return 'game_over', np.zeros([8, 8])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgyWP1k8JRFZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decide_move(board, logits):\n",
        "  biggest_diff = 1 #0\n",
        "  piece = []\n",
        "  to = []\n",
        "\n",
        "  for i in range(8):\n",
        "    for j in range(8):\n",
        "      #if abs(board[i, j] - logits[i, j]) > biggest_diff:\n",
        "      #if -(logits[i, j] - board[i, j]) > biggest_diff:\n",
        "      if board[i, j] > 0:\n",
        "        if logits[i, j] / board[i, j] < biggest_diff:\n",
        "          moves = get_possible_moves(board, [i, j])\n",
        "\n",
        "          for move in moves:\n",
        "            copy_board = np.copy(board)\n",
        "            copy_board[move[0], move[1]] = board[i, j]\n",
        "            copy_board[i, j] = e\n",
        "\n",
        "            if not is_check(flip(copy_board), N):\n",
        "              piece = [i, j]\n",
        "              to = [move[0], move[1]]\n",
        "\n",
        "  return piece, to"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TA2ibtmsFpa0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decide_move(board, logits):\n",
        "  biggest_diff = 0\n",
        "  piece = []\n",
        "  to = []\n",
        "\n",
        "  for i in range(8):\n",
        "    for j in range(8):\n",
        "      if board[i, j] > 0:\n",
        "        if 1 - logits[i, j, board[i, j]+p] > biggest_diff:\n",
        "          moves = get_possible_moves(board, [i, j])\n",
        "\n",
        "          smallest_diff = 0\n",
        "          for move in moves:\n",
        "            if logits[move[0], move[1], board[i, j]+p] > smallest_diff:\n",
        "              copy_board = np.copy(board)\n",
        "              copy_board[move[0], move[1]] = board[i, j]\n",
        "              copy_board[i, j] = e\n",
        "\n",
        "              if not is_check(flip(copy_board), N):\n",
        "                piece = [i, j]\n",
        "                to = [move[0], move[1]]\n",
        "\n",
        "  return piece, to"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iy7MovkO714Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def random_move(board):\n",
        "  I = list(range(8))\n",
        "  J = list(range(8))\n",
        "  np.random.shuffle(I)\n",
        "  np.random.shuffle(J)\n",
        "  piece = []\n",
        "  to = []\n",
        "\n",
        "  for i in I:\n",
        "    for j in J:\n",
        "      if board[i, j] > 0:\n",
        "        moves = get_possible_moves(board, [i, j])\n",
        "\n",
        "\n",
        "        np.random.shuffle(moves)\n",
        "\n",
        "        for move in moves:\n",
        "          copy_board = np.copy(board)\n",
        "          copy_board[move[0], move[1]] = board[i, j]\n",
        "          copy_board[i, j] = e\n",
        "\n",
        "          if not is_check(flip(copy_board), N):\n",
        "            piece = [i, j]\n",
        "            to = [move[0], move[1]]\n",
        "            break\n",
        "\n",
        "        if piece and to:\n",
        "          break\n",
        "\n",
        "    if piece and to:\n",
        "      break\n",
        "\n",
        "  return piece, to"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2JAuwFEBVxR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def is_check(board, piece):\n",
        "  coordinates = []\n",
        "\n",
        "  for i in range(8):\n",
        "    for j in range(8):\n",
        "      if board[i, j] == piece:\n",
        "        coordinates = [i, j]\n",
        "\n",
        "  check = False\n",
        "  for i in range(8):\n",
        "    for j in range(8):\n",
        "      if board[i, j] > 0 and not check:\n",
        "        moves = get_possible_moves(board, [i, j])\n",
        "        check = coordinates in moves\n",
        "\n",
        "  return check"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Oy0hHLEc1tc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_possible_moves(board, coordinates): #put together all moves that 'is_legal', are on the board and aren't taking your own pieces\n",
        "  legal_moves = []\n",
        "  for i in range(8):\n",
        "    for j in range(8):\n",
        "      if (board[coordinates[0], coordinates[1]] > 0 and board[i, j] <= 0) or (board[coordinates[0], coordinates[1]] < 0 and board[i, j] >= 0):\n",
        "        if is_legal(board, coordinates, [i, j]):\n",
        "          legal_moves.append([i, j])\n",
        "\n",
        "  return legal_moves"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-tchmQQcS5R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def is_legal(board, piece, move): #check if move is in a direction that the piece moves andif squares between start and finish are empty\n",
        "  if board[piece[0], piece[1]] == n: #KINGS\n",
        "    return abs(piece[0] - move[0]) <= 1 and abs(piece[1] - move[1]) <= 1\n",
        "\n",
        "  elif board[piece[0], piece[1]] == q: #QUEEN\n",
        "    if abs(piece[0] - move[0]) == 0:\n",
        "      if abs(piece[1] - move[1]) >= 2:\n",
        "        return np.all(board[min([piece[1], move[1]])+1 : max([piece[1], move[1]])] == e)\n",
        "      else:\n",
        "        return True\n",
        "    elif abs(piece[1] - move[1]) == 0:\n",
        "      if abs(piece[0] - move[0]) >= 2:\n",
        "        return np.all(board[min([piece[0], move[0]])+1 : max([piece[0], move[0]])] == e)\n",
        "      else:\n",
        "        return True\n",
        "    elif abs(piece[0] - move[0]) == abs(piece[1] - move[1]):\n",
        "      empty = True\n",
        "      for i in range(8):\n",
        "        for j in range(8):\n",
        "          if board[i, j] != e:\n",
        "            empty = False\n",
        "      return empty\n",
        "    else:\n",
        "      return False\n",
        "\n",
        "  elif board[piece[0], piece[1]] == r: #ROOK\n",
        "    if abs(piece[0] - move[0]) == 0:\n",
        "      if abs(piece[1] - move[1]) >= 2:\n",
        "        return np.all(board[min([piece[1], move[1]])+1 : max([piece[1], move[1]])] == e)\n",
        "      else:\n",
        "        return True\n",
        "    elif abs(piece[1] - move[1]) == 0:\n",
        "      if abs(piece[0] - move[0]) >= 2:\n",
        "        return np.all(board[min([piece[0], move[0]])+1 : max([piece[0], move[0]])] == e)\n",
        "      else:\n",
        "        return True\n",
        "    else:\n",
        "      return False\n",
        "\n",
        "  elif board[piece[0], piece[1]] == b: #BISHOP\n",
        "    if abs(piece[0] - move[0]) == abs(piece[1] - move[1]):\n",
        "      empty = True\n",
        "      for i in range(8):\n",
        "        for j in range(8):\n",
        "          if board[i, j] != e:\n",
        "            empty = False\n",
        "      return empty\n",
        "    else:\n",
        "      return False\n",
        "\n",
        "  elif board[piece[0], piece[1]] == k: #KNIGHT\n",
        "    return (abs(piece[0] - move[0]) == 2 and abs(piece[0] - move[0]) == 1) or (abs(piece[0] - move[0]) == 1 and abs(piece[0] - move[0]) == 2)\n",
        "\n",
        "  elif board[piece[0], piece[1]] == p: #PAWN\n",
        "    return ((move[0] - piece[0]) == 1 and abs(piece[1] - move[1]) == 0) or ((move[0] - piece[0]) == 1 and abs(piece[1] - move[1]) == 1 and board[move[0], move[1]] < 0)\n",
        "\n",
        "  else:\n",
        "    print('u fucked up')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PpGP7sN9-ex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_steps = 200\n",
        "games_to_play = 100\n",
        "max_depth = 100\n",
        "epochs = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1WrL7byDkRR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_path = \"training_0/cp.ckpt\"\n",
        "\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xox7Gbqw9e54",
        "colab_type": "code",
        "outputId": "67088873-bad2-4c1f-a5bd-2a1064e52b99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "for step in range(n_steps):\n",
        "  replay_memory = []\n",
        "\n",
        "  for game in range(games_to_play):\n",
        "    game_memory = []\n",
        "    board = init_board()\n",
        "    #print(\"NEW GAMEEEEEEEEEEE!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
        "\n",
        "    for depth in range(max_depth):\n",
        "      move, weights_arr = make_move(np.copy(board), False, step/n_steps)\n",
        "      if not (type(move) is np.ndarray):\n",
        "        win = 'black'\n",
        "        break\n",
        "      else:\n",
        "        game_memory.append([board, move, weights_arr])\n",
        "        board = np.copy(move)\n",
        "\n",
        "      move, weights_arr = make_move(np.copy(board), True, step/n_steps)\n",
        "      if not (type(move) is np.ndarray):\n",
        "        win = 'white'\n",
        "        break\n",
        "      else:\n",
        "        game_memory.append([flip(board), move, weights_arr])\n",
        "        board = np.copy(flip(move))\n",
        "\n",
        "    else:\n",
        "      win = 'white' if np.sum(board) > 0 else 'black'\n",
        "\n",
        "    replay_memory.append([win, game_memory]) \n",
        "\n",
        "\n",
        "  x = []\n",
        "  w = []\n",
        "  y = []\n",
        "\n",
        "  for game in replay_memory:\n",
        "    result, moves = game\n",
        "\n",
        "    for board, move, weights_arr in moves:\n",
        "      x.append(one_hot(board, 2*p+1))\n",
        "      w.append(np.tile(np.expand_dims(weights_arr, -1), [1, 1, 13]))\n",
        "      if result == 'white':\n",
        "        y.append(one_hot(move+p, 2*p+1))\n",
        "      else:\n",
        "        y.append(one_hot(board+p, 2*p+1))\n",
        "\n",
        "  x = np.array(x)\n",
        "  w = np.array(w)\n",
        "  y = np.array(y)\n",
        "  yw = np.stack([y, w], 1)\n",
        "\n",
        "  \n",
        "  #model.fit(x=[x, w], y=y, epochs = epochs, callbacks=[cp_callback])\n",
        "  #model.fit(x=x, y=y, epochs = epochs, callbacks=[cp_callback])\n",
        "  model.fit(x=x, y=yw, epochs = epochs, callbacks=[cp_callback])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 19690 samples\n",
            "Epoch 1/10\n",
            "19648/19690 [============================>.] - ETA: 0s - loss: 0.0061\n",
            "Epoch 00001: saving model to training_0/cp.ckpt\n",
            "19690/19690 [==============================] - 20s 1ms/sample - loss: 0.0061\n",
            "Epoch 2/10\n",
            " 9120/19690 [============>.................] - ETA: 7s - loss: 0.0031\n",
            "Epoch 00002: saving model to training_0/cp.ckpt\n",
            " 9184/19690 [============>.................] - ETA: 7s - loss: 0.0032"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-39d79c0a38a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[0;31m#model.fit(x=[x, w], y=y, epochs = epochs, callbacks=[cp_callback])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m   \u001b[0;31m#model.fit(x=x, y=y, epochs = epochs, callbacks=[cp_callback])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcp_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVI1QhLaDxC7",
        "colab_type": "code",
        "outputId": "cb63d575-deab-4c1f-ff2c-98fe974635dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.load_weights(checkpoint_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f4da0676d68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaAblc1Gg9ji",
        "colab_type": "code",
        "outputId": "6b5477de-cb2b-4a2c-d5ac-a969b3adc487",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "actuall = init_board()\n",
        "one, two = make_move(actuall, False, 1000)\n",
        "print(one)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 3  5  4  2  1  4  5  3]\n",
            " [ 6  6  6  6  6  6  6  0]\n",
            " [ 0  0  0  0  0  0  0  6]\n",
            " [ 0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0]\n",
            " [-6 -6 -6 -6 -6 -6 -6 -6]\n",
            " [-3 -5 -4 -2 -1 -4 -5 -3]]\n",
            "[[0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMSFhSJwmkUN",
        "colab_type": "code",
        "outputId": "a8eefe3f-f4d5-47a4-b85a-bf11ec701ee7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "one[6, 4] = e\n",
        "one[4, 4] = P\n",
        "one, two = make_move(one, False, 1000)\n",
        "print(one)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 3  5  4  2  1  4  5  0]\n",
            " [ 0  6  6  0  6  6  6  3]\n",
            " [ 6  0  0  6  0  0  0  6]\n",
            " [ 0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 -6 -6  0  0]\n",
            " [ 0  0  0  0  0  0  0  0]\n",
            " [-6 -6 -6 -6  0  0 -6 -6]\n",
            " [-3 -5 -4 -2 -1 -4 -5 -3]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgsvfLBHmz91",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}